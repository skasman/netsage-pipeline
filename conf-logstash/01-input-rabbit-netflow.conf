#{"event_type": "purge", "label": "docker", "as_src": 0, "as_dst": 0, "comms": "", "ecomms": "", "lcomms": "", "as_path": "", "local_pref": 0, "med": 0, "peer_as_src": 0, "peer_as_dst": 0, "peer_ip_src": "172.23.0.1", "peer_ip_dst": "", "iface_in": 909, "iface_out": 517, "mpls_vpn_rd": "0:0:0", "mpls_pw_id": 0, "ip_src": "87.100.13.241", "ip_dst": "106.89.180.131", "port_src": 55664, "port_dst": 443, "ip_proto": "tcp", "mpls_label_top": 0, "mpls_label_bottom": 0, "mpls_stack_depth": 0, "timestamp_start": "1574664912.000000", "timestamp_end": "1574665005.000000", "vrfid_ingress": "0", "vrfid_egress": "0", "vrfname": "", "packets": 700, "bytes": 39200, "writer_id": "default_amqp/9"}


input {
    # Normally, input events are flows from the named rabbit queue on LOCALHOST
    # (The 'netsage_deidentfier_raw' rabbit queue may contain flows from netsage-netflow-importer-daemon and/or tstat_send.)
    # The user=>"${rabbitmq_input_username} format  works if the rabbitmq username and password are in the logstash keystore as
    # rabbitmq_input_username and rabbitmq_input_pw. You can also just type in the username and pw here, in quotes.
    # Replace the queue and key name, if needed. 
    rabbitmq{
        host     => "${rabbitmq_input_host:localhost}"
        user     => "${rabbitmq_input_username:guest}"	        
        password => "${rabbitmq_input_pw:guest}"
        queue    => 'poller_queue'
        key      => 'poller_queue'
        exchange => 'amq.direct'
        durable  => true
        connection_timeout => 10000
        subscription_retry_interval_seconds => 5
        add_field => {
            '[meta][flow_type]' => 'netflow'
        }
    }

    # For testing - Read JSON from a file
    # file {
    #   path => "/..../events.sample"
    #   sincedb_path => "/dev/null"       # to not keep track of processed lines 
    #   start_position => "beginning"     # to always redo all lines in the file 
    #   codec => "json"                   # parses JSON into logstash fields
    # }
}


